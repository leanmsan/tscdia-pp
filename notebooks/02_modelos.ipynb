{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5532aa71",
   "metadata": {},
   "source": [
    "# 02 - Desarrollo y Evaluación de Modelos\n",
    "\n",
    "Este notebook contiene el desarrollo, entrenamiento y evaluación de modelos de machine learning.\n",
    "\n",
    "## Objetivos:\n",
    "- Preparar datos para modelado\n",
    "- Entrenar diferentes modelos\n",
    "- Evaluar y comparar rendimiento\n",
    "- Optimizar hiperparámetros\n",
    "- Seleccionar el mejor modelo\n",
    "- Guardar modelo final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d5397d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar librerías necesarias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Importar funciones personalizadas\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "from etl.data_loader import load_csv_data, load_config\n",
    "from etl.data_cleaner import clean_missing_values, remove_outliers\n",
    "from features.feature_engineering import encode_categorical_variables, scale_numerical_features\n",
    "from models.model_training import (\n",
    "    split_data, train_classification_model, train_regression_model,\n",
    "    evaluate_classification_model, evaluate_regression_model,\n",
    "    save_model, load_model\n",
    ")\n",
    "from utils.helpers import print_metrics, setup_logging\n",
    "\n",
    "print(\"Librerías importadas correctamente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89eb0d16",
   "metadata": {},
   "source": [
    "## 1. Carga y Preparación de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5542544",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar configuración\n",
    "config = load_config('../config.yaml')\n",
    "\n",
    "# Cargar datos procesados (ajustar ruta según tu dataset)\n",
    "# df = load_csv_data('../data/processed/cleaned_data.csv')\n",
    "# print(f\"Datos cargados: {df.shape}\")\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bfa65e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir variables objetivo y características\n",
    "# target_column = 'target'  # Ajustar según tu caso\n",
    "# feature_columns = [col for col in df.columns if col != target_column]\n",
    "\n",
    "# X = df[feature_columns]\n",
    "# y = df[target_column]\n",
    "\n",
    "# print(f\"Características: {X.shape}\")\n",
    "# print(f\"Variable objetivo: {y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff35a75",
   "metadata": {},
   "source": [
    "## 2. División de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be752ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir datos en entrenamiento y prueba\n",
    "# X_train, X_test, y_train, y_test = split_data(\n",
    "#     X, y, \n",
    "#     test_size=config['model']['test_size'],\n",
    "#     random_state=config['model']['random_state']\n",
    "# )\n",
    "\n",
    "# print(f\"Entrenamiento: {X_train.shape}\")\n",
    "# print(f\"Prueba: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a01bfd",
   "metadata": {},
   "source": [
    "## 3. Entrenamiento de Modelos Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f18c295",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diccionario para almacenar modelos y resultados\n",
    "models = {}\n",
    "results = {}\n",
    "\n",
    "# Para clasificación (ajustar según tu problema)\n",
    "# model_configs = {\n",
    "#     'Random Forest': {'model_type': 'random_forest', 'n_estimators': 100},\n",
    "#     'Logistic Regression': LogisticRegression(random_state=42),\n",
    "#     'SVM': SVC(random_state=42, probability=True)\n",
    "# }\n",
    "\n",
    "# Para regresión (ajustar según tu problema)\n",
    "# model_configs = {\n",
    "#     'Random Forest': {'model_type': 'random_forest', 'n_estimators': 100},\n",
    "#     'Linear Regression': LinearRegression(),\n",
    "#     'SVR': SVR()\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3afd8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar modelos de clasificación\n",
    "# for name, config in model_configs.items():\n",
    "#     print(f\"Entrenando {name}...\")\n",
    "#     \n",
    "#     if isinstance(config, dict):\n",
    "#         # Usar funciones personalizadas\n",
    "#         model = train_classification_model(X_train, y_train, **config)\n",
    "#     else:\n",
    "#         # Usar modelo de sklearn directamente\n",
    "#         model = config\n",
    "#         model.fit(X_train, y_train)\n",
    "#     \n",
    "#     models[name] = model\n",
    "#     \n",
    "#     # Evaluar modelo\n",
    "#     if hasattr(model, 'predict'):\n",
    "#         metrics = evaluate_classification_model(model, X_test, y_test)\n",
    "#         results[name] = metrics\n",
    "#         print_metrics(metrics, f\"Métricas de {name}\")\n",
    "#     \n",
    "#     print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e93b073a",
   "metadata": {},
   "source": [
    "## 4. Comparación de Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7052b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear DataFrame de comparación\n",
    "# comparison_df = pd.DataFrame(results).T\n",
    "# comparison_df = comparison_df.sort_values('accuracy', ascending=False)  # Para clasificación\n",
    "# # comparison_df = comparison_df.sort_values('r2_score', ascending=False)  # Para regresión\n",
    "\n",
    "# print(\"Comparación de Modelos:\")\n",
    "# print(comparison_df)\n",
    "\n",
    "# # Visualizar comparación\n",
    "# fig, ax = plt.subplots(figsize=(12, 6))\n",
    "# comparison_df.plot(kind='bar', ax=ax)\n",
    "# plt.title('Comparación de Métricas por Modelo')\n",
    "# plt.xlabel('Modelos')\n",
    "# plt.ylabel('Puntuación')\n",
    "# plt.xticks(rotation=45)\n",
    "# plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe672018",
   "metadata": {},
   "source": [
    "## 5. Análisis Detallado del Mejor Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c90ad2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionar mejor modelo\n",
    "# best_model_name = comparison_df.index[0]\n",
    "# best_model = models[best_model_name]\n",
    "\n",
    "# print(f\"Mejor modelo: {best_model_name}\")\n",
    "# print_metrics(results[best_model_name], f\"Métricas detalladas de {best_model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e364938",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz de confusión (para clasificación)\n",
    "# y_pred = best_model.predict(X_test)\n",
    "# cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# plt.figure(figsize=(8, 6))\n",
    "# sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "# plt.title(f'Matriz de Confusión - {best_model_name}')\n",
    "# plt.xlabel('Predicción')\n",
    "# plt.ylabel('Real')\n",
    "# plt.show()\n",
    "\n",
    "# # Reporte de clasificación\n",
    "# print(\"\\nReporte de Clasificación:\")\n",
    "# print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5abd3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Curva ROC (para clasificación binaria)\n",
    "# if hasattr(best_model, 'predict_proba') and len(np.unique(y_test)) == 2:\n",
    "#     y_proba = best_model.predict_proba(X_test)[:, 1]\n",
    "#     fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
    "#     auc_score = roc_auc_score(y_test, y_proba)\n",
    "#     \n",
    "#     plt.figure(figsize=(8, 6))\n",
    "#     plt.plot(fpr, tpr, label=f'ROC Curve (AUC = {auc_score:.3f})')\n",
    "#     plt.plot([0, 1], [0, 1], 'k--', label='Random')\n",
    "#     plt.xlabel('Tasa de Falsos Positivos')\n",
    "#     plt.ylabel('Tasa de Verdaderos Positivos')\n",
    "#     plt.title(f'Curva ROC - {best_model_name}')\n",
    "#     plt.legend()\n",
    "#     plt.grid(True)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113ad3ba",
   "metadata": {},
   "source": [
    "## 6. Importancia de Características"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf1094a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importancia de características (para modelos que lo soporten)\n",
    "# if hasattr(best_model, 'feature_importances_'):\n",
    "#     feature_importance = pd.DataFrame({\n",
    "#         'feature': feature_columns,\n",
    "#         'importance': best_model.feature_importances_\n",
    "#     }).sort_values('importance', ascending=False)\n",
    "#     \n",
    "#     plt.figure(figsize=(10, 8))\n",
    "#     top_features = feature_importance.head(15)\n",
    "#     sns.barplot(data=top_features, x='importance', y='feature')\n",
    "#     plt.title(f'Top 15 Características Más Importantes - {best_model_name}')\n",
    "#     plt.xlabel('Importancia')\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n",
    "#     \n",
    "#     print(\"Top 10 características más importantes:\")\n",
    "#     print(feature_importance.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb01bd4",
   "metadata": {},
   "source": [
    "## 7. Optimización de Hiperparámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd560ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid Search para optimización de hiperparámetros\n",
    "# if best_model_name == 'Random Forest':\n",
    "#     param_grid = {\n",
    "#         'n_estimators': [100, 200, 300],\n",
    "#         'max_depth': [10, 20, None],\n",
    "#         'min_samples_split': [2, 5, 10],\n",
    "#         'min_samples_leaf': [1, 2, 4]\n",
    "#     }\n",
    "#     \n",
    "#     grid_search = GridSearchCV(\n",
    "#         best_model, param_grid, cv=5, \n",
    "#         scoring='accuracy', n_jobs=-1, verbose=1\n",
    "#     )\n",
    "#     \n",
    "#     print(\"Optimizando hiperparámetros...\")\n",
    "#     grid_search.fit(X_train, y_train)\n",
    "#     \n",
    "#     print(f\"Mejores parámetros: {grid_search.best_params_}\")\n",
    "#     print(f\"Mejor puntuación CV: {grid_search.best_score_:.4f}\")\n",
    "#     \n",
    "#     # Evaluar modelo optimizado\n",
    "#     optimized_model = grid_search.best_estimator_\n",
    "#     optimized_metrics = evaluate_classification_model(optimized_model, X_test, y_test)\n",
    "#     print_metrics(optimized_metrics, \"Métricas del Modelo Optimizado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af85d3a2",
   "metadata": {},
   "source": [
    "## 8. Validación Cruzada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41b9877",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validación cruzada del mejor modelo\n",
    "# cv_scores = cross_val_score(best_model, X_train, y_train, cv=5, scoring='accuracy')\n",
    "\n",
    "# print(f\"Puntuaciones de Validación Cruzada: {cv_scores}\")\n",
    "# print(f\"Promedio CV: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\")\n",
    "\n",
    "# # Visualizar distribución de puntuaciones CV\n",
    "# plt.figure(figsize=(8, 6))\n",
    "# plt.boxplot(cv_scores)\n",
    "# plt.title('Distribución de Puntuaciones de Validación Cruzada')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.grid(True)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e56a95",
   "metadata": {},
   "source": [
    "## 9. Guardar Modelo Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56a825a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar el mejor modelo\n",
    "# model_filename = f\"../models/{best_model_name.lower().replace(' ', '_')}_final.joblib\"\n",
    "# save_model(best_model, model_filename)\n",
    "\n",
    "# # Guardar también métricas\n",
    "# metrics_filename = f\"../models/{best_model_name.lower().replace(' ', '_')}_metrics.json\"\n",
    "# import json\n",
    "# with open(metrics_filename, 'w') as f:\n",
    "#     json.dump(results[best_model_name], f, indent=2)\n",
    "\n",
    "# print(f\"Modelo guardado como: {model_filename}\")\n",
    "# print(f\"Métricas guardadas como: {metrics_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9251c2",
   "metadata": {},
   "source": [
    "## 10. Resumen y Conclusiones\n",
    "\n",
    "### Resultados Principales:\n",
    "1. **Mejor modelo**: [Nombre del mejor modelo]\n",
    "2. **Métricas principales**: [Accuracy, Precision, Recall, F1-Score]\n",
    "3. **Características más importantes**: [Top 5 características]\n",
    "\n",
    "### Análisis:\n",
    "- **Rendimiento**: [Comentarios sobre el rendimiento del modelo]\n",
    "- **Sobreajuste**: [Análisis de posible overfitting]\n",
    "- **Generalización**: [Capacidad de generalización]\n",
    "\n",
    "### Próximos pasos:\n",
    "1. Implementar el modelo en producción\n",
    "2. Monitorear rendimiento en datos nuevos\n",
    "3. Reentrenar periódicamente\n",
    "4. Considerar ensemble methods si es necesario"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
